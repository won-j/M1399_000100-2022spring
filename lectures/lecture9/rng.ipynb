{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(scatterplot3d)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random number generation\n",
    "\n",
    "## Uniform random number generation\n",
    "\n",
    "### Goal\n",
    "\n",
    "To generate $U_i \\stackrel{iid}{\\sim} \\text{unif}(0, 1)$.\n",
    "\n",
    "* Basis for all other random number generation\n",
    "* **Fact: NO RANDOM NUMBER IN COMPUTER** --- only look random (PSEUDO-RANDOM)\n",
    "\n",
    "### Congruential generator\n",
    "\n",
    "\\begin{align*}\n",
    "    x_{i+1} &= a x_i \\mod m, \\quad i=1, 2, \\dotsc \\\\\n",
    "    u_i &= x_i / m.\n",
    "\\end{align*}\n",
    "\n",
    "* Modulus $m$ is a large prime number.\n",
    "* Multiplier $a$ is a positive integer between 2 and $m-1$.\n",
    "* Map $f: x \\mapsto ax \\mod m$ maps $\\{1, \\dotsc, m-1\\}$ onto itself and is one-to-one:\n",
    "    - Suppose $x\\in\\{1, \\dotsc, m-1\\}$. Then $f(x) \\neq 0$ since $a$ and $m$ are relatively prime hence $ax$ is not a multiple of $m$. Thus $f$ maps $\\{1, , \\dotsc, m-1\\}$ to $\\{1, , \\dotsc, m-1\\}$.\n",
    "    - If $ay = ax \\mod m$, then $a(y - x) = m k$ for some integer $k$. Since $a$ and $m$ are relatively prime,  $y - x = m l$ for some interger $l$. That is, $x = y \\mod m$. Hence map $f$ is one-to-one.\n",
    "    - Since $f$ maps $\\{1, , \\dotsc, m-1\\}$ to $\\{1, , \\dotsc, m-1\\}$ and one-to-one, $f$ is also onto.\n",
    "    \n",
    "* Note\n",
    "\\begin{align*}\n",
    "    x_1 &= a x_0 \\mod m \\\\\n",
    "    x_2 &= a x_1 \\mod m = a^2 x_0 \\mod m \\\\\n",
    "    x_3 &= a x_2 \\mod m = a^3 x_0 \\mod m \\\\\n",
    "    & \\vdots \\\\\n",
    "    x_n &= a x_{n-1} \\mod m = a^n x_0 \\mod m\n",
    "\\end{align*}\n",
    "Hence if $a^n = 1 \\mod m$ for some $n$, then \n",
    "$$\n",
    "    x_n = x_0 \\mod m\n",
    "$$\n",
    "and the (pseudo)random number generator repeats the sequence. The number $n$ is called the **period** of the RNG, and $x_0$ is called the **seed**.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2020)  # set 2020th seed; does not mean x_0 = 2020\n",
    "runif(5)\n",
    "set.seed(2020)  # same seed results in same \"random\" sequence\n",
    "runif(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Primitive root of unity\n",
    "    - Fermat's little theorem: $a^{m} = a \\mod m$.\n",
    "    - Since $a$ is not divisible by $m$, we have $a^{m-1} = 1 \\mod m$.\n",
    "    - Thus the period $n$ satisfies $n \\le m - 1$.\n",
    "    - *Primitive* root of unity: $a$ such that $n = m - 1$\n",
    "    - If $a$ is primitive, then $x_1, x_2, \\dotsc, x_{m-1}$ is a permutation of $\\{1, 2, \\dotsc, m-1\\}$.\n",
    "    - For $m=2^{31} - 1$ (Mersenne prime), $a=7^5 = 16807$ is primitive, leading to the period of $2^{31} - 2$ = `2,147,483,646`. This RNG was used in early versions of MATLAB (up to v4).\n",
    "    \n",
    "Good RNGs should have long periods, and should give samples which appear to be drawn from a uniform distribution. If the size of the sample is much less than the period of the RNG, then the sample should appear random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation\n",
    "\n",
    "* Ideally, a pseudorandom number sequence should look i.i.d. If we take the first $p$ values to form an $p$-dimensional vector, the second $p$ values to form a second $p$-dimensional vector, etc, then these vectors should fill the $p$-dimensional hypercube uniformly.\n",
    "\n",
    "* However, by construction the sequence generated by congruential generators depends on the previous value, hence tends to be correlated.\n",
    "\n",
    "* It is known that congruential generators tend to give $p$-dimensional vectors that concentrate lower-dimensional hyperplanes, for some $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM System/360 RANDU generator\n",
    "# a = 2^16 + 3 = 65539\n",
    "# m = 2^31\n",
    "n <- 2000\n",
    "a <- 65539\n",
    "m <- 2^31\n",
    "u <- vector(length=n)\n",
    "u[1] <- 1\n",
    "for (i in seq_len(n-1)) {\n",
    "    u[i+1] <- a * u[i] %% m\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot3d(u[1:(n-2)], u[2:(n-1)], u[3:n], angle=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early MATLAB RNG\n",
    "# a = 7^5\n",
    "# m = 2^31 - 1\n",
    "n <- 2000\n",
    "a2 <- 7^5\n",
    "m2 <- 2^31 - 1\n",
    "v <- vector(length=n)\n",
    "v[1] <- 1\n",
    "for (i in seq_len(n-1)) {\n",
    "    v[i+1] <- a2 * v[i] %% m2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot3d(v[1:(n-2)], v[2:(n-1)], v[3:n], angle=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple modification is to introduce *shuffling* in the sequence, which we won't cover in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R's RNG\n",
    "\n",
    "* R uses the Mersenne-Twister as the default RNG. This RNG was developed by Matsumoto and Nishimura in 1998, and is the first algorithm whose period ($2^{19937} - 1$) exceeds the number of electron spin changes since the creation of the Universe ($10^{6000}$ against $10^{120}$)!\n",
    "\n",
    "* Mersenne-Twister guarantees 623 consecutive dimensions to be equidistributed (over the whole period). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNGkind()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation methods\n",
    "\n",
    "From now on, we assume the the problem of generating uniform random numbers has been solved for practical purposes.\n",
    "\n",
    "### Inverse CDF method\n",
    "\n",
    "For a random variable $X$, let $F$ be its cumulative distribution function (CDF), that is, $F(x) = P(X \\le x)$.\n",
    "Recall that $F$ is right-continuous and nondecreasing. Also, if $F$ is strictrly increasing, random variable $F(X)$ is uniformly distributed on $[0, 1]$. Below, we generalize this result.\n",
    "\n",
    "The inverse CDF of $X$ is defined as\n",
    "$$\n",
    "    F^{-1}(u) = \\inf\\{x: F(x) \\ge u\\}, \n",
    "    ,\n",
    "$$\n",
    "which coincides the usual inverse of $F$ if $F$ is strictly increasing.\n",
    "\n",
    "**Proposition 1**. Let $X$ be a random variable with CDF $F$. Then the following holds.\n",
    "1. If $F$ is continuous, then $U = F(X)$ is a uniform random variable on $[0, 1]$.\n",
    "2. If $F$ is not continous, then $P[F(X) \\le y] \\le y$ for all $y \\in [0, 1]$.\n",
    "3. If $U$ is uniform on $[0, 1]$, then $F^{-1}(U)$ has CDF $F$.\n",
    "    \n",
    "*Proof*. \n",
    "* Part 1: We will show that \n",
    "$$\n",
    "    P[F(X) \\le F(t)] = F(t)\n",
    "    \\tag{*}\n",
    "$$\n",
    "for any $t$. Suppose for now this is true. \n",
    "\n",
    " Let $u \\in (0, 1)$. Then by continuity of $F$, there is $y$ such that $F(y) = u$. By (*), \n",
    "$$\n",
    "    P[F(X) \\le u] = P[F(X) \\le F(y)] = F(y) = u.\n",
    "$$\n",
    "\n",
    "* Part 3: It suffices to show that $\\{F^{-1}(U) \\le t\\} = \\{U \\le F(t)\\}$. If $F^{-1}(u)=\\inf\\{x: F(x) \\ge u\\} \\le t$, then by the monotonicity and right-continuity of $F$, the set $\\{x: F(x) \\ge u\\}$ is an half-closed interval containing its left endpoint, which is $F^{-1}(u)$. Hence $F(F^{-1}(u)) \\ge u$. Since $F^{-1}(u) \\le t$, again by monotonicity of $F$, it follows that $u \\le F(F^{-1}(u)) \\le F(t)$. Conversely, if $u \\le F(t)$, then by definition $F^{-1}(u) \\le t$.\n",
    "\n",
    "* Part 2: by part 3, $X\\stackrel{d}{=}F^{-1}(U)$, where $U$ is uniform on $[0, 1]$. Since $x=F^{-1}(u)$ implies $u \\le F(x)$, \n",
    "$$\n",
    "    P[F(X) \\le y] \\le P(U \\le y) = y.\n",
    "$$\n",
    "\n",
    "* It remains to show (*). Monotonicity of $F$ yields $\\{X > t\\} \\subset \\{F(X) \\ge F(t)\\}$. Hence $\\{X > t \\} \\cap \\{F(X) < F(t) \\} = \\emptyset$. Likewise $\\{X \\le t\\} \\cap \\{F(X) > F(t)\\} = \\emptyset\\}$. Then,\n",
    "\\begin{align*}\n",
    "    \\{X > t\\} \\cap \\{F(X) \\le F(t)\\} &=\n",
    "    [\\{X > t\\} \\cap \\{F(X) < F(t) \\}] \\cup [\\{X > t\\} \\cap \\{F(X) = F(t)\\}] \\\\\n",
    "    &= \\{X > t\\} \\cap \\{F(X) = F(t)\\}\n",
    "    \\\\\n",
    "    \\{X \\le t\\} \\cap \\{F(X) \\le F(t)\\} &= \\{X \\le t\\} \\cap \\{F(X) > F(t)\\}^c \n",
    "    = \\{X \\le t\\}\n",
    "\\end{align*}\n",
    "So,\n",
    "$$\n",
    "    \\{F(X) \\le F(t) \\}  = \\{X \\le t\\} \\cup [\\{X > t\\} \\cap \\{F(X) = F(t)\\}] =: A \\cup B\n",
    "    .\n",
    "$$\n",
    "Obviously events $A$ and $B$ are disjoint. However, event $B$ corresponds to the values $x$ of $X$ with which $F(x)$ is constant. Hence $P(B)=0$. Therefore,\n",
    "$$\n",
    "    P[F(X) \\le F(t)] = P(A) + P(B) = P(A) = P(X \\le t) = F(t).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exponential distribution\n",
    "\n",
    "* CDF $F(x) = 1 - e^{-\\lambda x}$ yields $F^{-1}(u) = -\\frac{1}{\\lambda}\\log u$ on $(0, 1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exp(1)\n",
    "n <- 1000\n",
    "u <- runif(n)\n",
    "x <- -log(u)\n",
    "expdata <- data.frame(x)\n",
    "plt <- ggplot(expdata, aes(x=x)) +  \n",
    "    geom_histogram(binwidth=0.25, fill=\"white\", color=\"black\") + \n",
    "    geom_density(aes(y=0.25 * ..count..), color=\"purple\")\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cauchy distribution\n",
    "\n",
    "From the density of the Cauchy distribution\n",
    "$$\n",
    "    f(x) = \\frac{\\beta}{\\pi(\\beta^2 + (x-\\mu)^2)},\n",
    "$$\n",
    "its CDF is $F(x) = \\frac{1}{2} + \\frac{1}{\\pi}\\tan^{-1}\\left(\\frac{x-\\mu}{\\beta}\\right)$. Thus\n",
    "$$\n",
    "    F^{-1}(u) = \\mu + \\beta\\tan(\\pi u - \\pi/2) = \\mu - \\frac{\\beta}{\\tan(\\pi u)}\n",
    "    .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard Cauchy (beta=1, mu=0)\n",
    "n <- 1000\n",
    "u <- runif(n)\n",
    "x <- -1/tan(pi * u)\n",
    "#hist(x, breaks=40)\n",
    "cauchydata <- data.frame(x)\n",
    "plt <- ggplot(cauchydata, aes(x=x)) +  \n",
    "    geom_histogram(binwidth=10, fill=\"white\", color=\"black\") + \n",
    "    geom_density(aes(y=10 * ..count..), color=\"purple\") + \n",
    "    xlim(-200, 200)\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrete uniform distribution \n",
    "\n",
    "$X \\sim \\text{unif}(\\{1, 2, \\dotsc, k\\})$. It is easy to verify $F(x) = \\frac{1}{k}\\lfloor x \\rfloor$ for $x \\in [0, n]$ and $F^{-1}(u)=\\lceil ku \\rceil$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k <- 10\n",
    "n <- 1000\n",
    "u <- runif(n)\n",
    "x <- ceiling(k * u)\n",
    "table(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geometric distribution \n",
    "\n",
    "If $X \\sim \\text{geom}(p)$, then its probability mass functin $p(x) = (1-p)^{x-1}p$.\n",
    "\n",
    "For $Y \\sim \\text{Exp}(\\lambda)$, \n",
    "\\begin{align*}\n",
    "    P(\\lceil Y \\rceil = k) &= P(k-1 < Y \\le k) = F_Y(k) - F_Y(k-1) = (1 - e^{-\\lambda k}) - (1 - e^{-\\lambda(k-1)}) \\\\\n",
    "   &=  e^{-\\lambda(k-1)}(1 - e^{-\\lambda}) \\\\\n",
    "   &- (1 - p)^{k-1} p\n",
    "\\end{align*}\n",
    "if $\\lambda$ satisfies $p = 1 - e^{-\\lambda}$, or $\\lambda = -\\log(1-p)$.\n",
    "\n",
    "For this $\\lambda$, $X = \\lceil Y \\rceil = \\lceil -\\frac{1}{\\lambda}\\log U \\rceil = \\lceil \\frac{\\log U}{\\log(1-p)}\\rceil$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gengeom <- function(p, nsamp=1) {\n",
    "    u <- runif(nsamp)\n",
    "    y <- log(u) / log(1 - p)\n",
    "    ceiling(y)\n",
    "}    \n",
    "nsamp <- 1000\n",
    "p <- 0.3\n",
    "x <- gengeom(p, nsamp)\n",
    "geomdata <- data.frame(x)\n",
    "plt <- ggplot(geomdata, aes(x=x)) + geom_histogram(binwidth=0.25)\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal random numbers\n",
    "\n",
    "For $X \\sim N(0, 1)$, inverse CDF $\\Phi^{-1}$ does not have a closed form.\n",
    "\n",
    "#### Box-Muller\n",
    "\n",
    "Generates $X, Y \\stackrel{iid}{\\sim} N(0, 1)$.\n",
    "\n",
    "Transforms the random Cartesian coordinates $(X, Y)$ to polar coorinates $(R, \\Theta)$. Since $(X, Y)=(R\\cos\\Theta, R\\sin\\Theta)$,\n",
    "$$\n",
    "    \\iint f_{XY}(x, y)dxdy = \\frac{1}{2\\pi}\\exp(-\\frac{x^2 + y^2}{2})dxdy\n",
    "    = \\iint \\frac{1}{2\\pi}\\exp(-\\frac{r^2}{2})rdrd\\theta\n",
    "    .\n",
    "$$\n",
    "\n",
    "Hence $R$ has density $f_R(r) = r\\exp(-\\frac{r^2}{2})$ and $\\Theta$ is uninform on $[0, 2\\pi]$. Since\n",
    "$$\n",
    "    P(R > \\rho) = P(R^2 > \\rho^2) = \\int_\\rho^{\\infty} r\\exp(-\\frac{r^2}{2})dr = \\exp(-\\frac{1}{2}\\rho^2),\n",
    "$$\n",
    "random variable $R^2$ is exponentially distributed with $\\lambda = 1/2$.\n",
    "\n",
    "Thus for independent $U, V \\sim \\text{unif}(0, 1)$, set\n",
    "$$\n",
    "    R = (-2\\log U)^{1/2}, \\quad \\Theta = 2\\pi V\n",
    "    .\n",
    "$$\n",
    "Then $(X, Y) = (R\\cos\\Theta, R\\sin\\Theta)$ are independently $N(0, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxmuller <- function(nsamp) {\n",
    "    n <- ceiling(nsamp / 2)\n",
    "    u <- runif(n)\n",
    "    v <- runif(n)\n",
    "    r <- sqrt(-2 * log(u))\n",
    "    theta <- 2 * pi * v\n",
    "    x <- r * cos(theta)\n",
    "    y <- r * sin(theta)\n",
    "    samp <- c(x, y)\n",
    "    samp[seq_len(nsamp)]\n",
    "}\n",
    "#hist(c(x, y))\n",
    "n <- 1000\n",
    "normdata1 <- data.frame(x = boxmuller(n))\n",
    "plt <- ggplot(normdata1, aes(x=x)) +  \n",
    "    geom_histogram(binwidth=0.25, fill=\"white\", color=\"black\") + \n",
    "    geom_density(aes(y=0.25 * ..count..), color=\"purple\")\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marsaglia\n",
    "\n",
    "* From the Box-Muller transformation, we learned that if $R^2 \\sim \\text{Exp}(1/2)$ and $\\Theta\\sim\\text{unif}(0, 2\\pi)$ and they are independent, $(R\\cos\\Theta, R\\sin\\Theta)$ are i.i.d. standard normal. \n",
    "\n",
    "* On the other hand, if a random point $(U, V)$ is uniformly distributed on the unit disk, and let $(U, V) = (T\\cos\\Phi, T\\sin\\Phi)$, then\n",
    "$$\n",
    "    P(T^2 \\le t^2, 0 \\le \\Phi \\le \\phi) = \n",
    "    \\frac{t^2\\phi}{2\\pi}, \\quad t^2 \\le 1, ~ \\phi \\in (0, 2\\pi) \\\\\n",
    "$$\n",
    "which means that $T^2 = U^2 + V^2 \\sim \\text{unif}(0, 1)$, $\\Phi \\sim \\text{unif}(0, 2\\pi)$, and they are independent.\n",
    "\n",
    "* Therefore, if we sample $(U, V)$ uniformly from the unit disk, and set $T = \\sqrt{U^2 + V^2}$, $\\cos\\Phi = U/T$, $\\sin\\Phi=V/T$, then $T^2\\sim\\text{unif}(0,1)$ and $-2\\log T^2$ is identically distributed to $R^2$, i.e., $\\text{Exp}(1/2)$, and $\\Phi$ is identically distributed to $\\Theta$, i.e., uniform on $(0, 2\\pi)$. Therefore, if we set $(X, Y)$ such that\n",
    "$$\n",
    "    X = \\sqrt{-2\\log T^2}\\frac{U}{T},\n",
    "    \\quad\n",
    "    Y = \\sqrt{-2\\log T^2}\\frac{V}{T},\n",
    "$$\n",
    "then $X, Y$ are i.i.d. standard normal.\n",
    "\n",
    "* One way to sample from the unit disk is to sample $(U, V)$ from $\\text{unif}[-1, 1]\\times\\text{unif}[-1, 1]$, and discard the sample if $U^2 + V^2 > 1$ and resample (see acceptance-rejection sampling below).\n",
    "\n",
    "* Algorithm:\n",
    "    1. $U, V \\stackrel{iid}{\\sim} \\text{unif}[-1, 1]$;\n",
    "    2. If $T = \\sqrt{U^2 + V^2} > 1$, go to 1;\n",
    "    3. Set $X = \\sqrt{-2\\log T^2}\\frac{U}{T}$ and $Y = \\sqrt{-2\\log T^2}\\frac{V}{T}$.\n",
    "    \n",
    "* This method avoids the trigonometric function evaluations of the Box-Muller, but uses $4/\\pi$ as many random pairs on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marsaglia <- function(nsamp) {\n",
    "    n <- ceiling(nsamp / 2)\n",
    "    it <- 0\n",
    "    x <- numeric(n)\n",
    "    y <- numeric(n)\n",
    "    while (it < n) {\n",
    "        u <- 2 * runif(1) - 1\n",
    "        v <- 2 * runif(1) - 1\n",
    "        tau <- sqrt(u^2 + v^2)\n",
    "        if (tau > 1) next\n",
    "        x[it] <- sqrt(-4 * log(tau)) * u / tau\n",
    "        y[it] <- sqrt(-4 * log(tau)) * v / tau\n",
    "        it <- it + 1\n",
    "    }\n",
    "    samp <- c(x, y)\n",
    "    samp[seq_len(nsamp)]    \n",
    "}\n",
    "n <- 1000\n",
    "normdata2 <- data.frame(x = marsaglia(n))\n",
    "plt <- ggplot(normdata2, aes(x=x)) +  \n",
    "    geom_histogram(binwidth=0.25, fill=\"white\", color=\"black\") + \n",
    "    geom_density(aes(y=0.25 * ..count..), color=\"purple\")\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random numbers by definition\n",
    "\n",
    "### Bernoulli\n",
    "\n",
    "1. Set the success probability $p$\n",
    "2. Generate $U \\sim \\text{unif}(0, 1)$.\n",
    "3. Let $X = \\mathbb{I}_{\\{U \\le p\\}}$.\n",
    "4. Then $X \\sim \\text{Ber}(p)$.\n",
    "\n",
    "### Binomial\n",
    "\n",
    "1. Set the success probability $p$\n",
    "2. Generate $n$ independent $X_i \\sim \\text{Ber}(p)$.\n",
    "3. Let $X_n = \\sum_{i=1}^n X_i$.\n",
    "4. Then $X_n \\sim B(n, p)$.\n",
    "\n",
    "### Negative binomial\n",
    "\n",
    "1. Set the success probability $p$\n",
    "2. Generate $r$ independent $X_i \\sim \\text{Geom}(p)$.\n",
    "3. Let $X_r = \\sum_{i=1}^r X_i$.\n",
    "4. Then $X_r \\sim \\text{NegBin}(r, p)$.\n",
    "\n",
    "### Poisson\n",
    "\n",
    "1. Generate $U_i \\stackrel{iid}{\\sim} \\text{unif}(0, 1)$.\n",
    "2. Find $N$ such that $\\prod_{i=1}^N U_i \\ge e^{-\\lambda} > \\prod_{i=1}^{N+1} U_i$.\n",
    "3. Then $N \\sim \\text{Poi}(\\lambda)$.\n",
    "\n",
    "- This is because $T_i = -\\frac{1}{\\lambda}\\log U_i \\stackrel{iid}{\\sim} \\text{Exp}(\\lambda)$,\n",
    "and is the waiting time between the $i-1$st and the $i$th event of the Poisson counting process $N(t) \\sim \\text{Poi}(\\lambda t)$.\n",
    "- That is, $N \\sim \\text{Poi}(\\lambda) \\iff T_1 + \\dotsc + T_N \\le 1 < T_1 + \\dotsc + T_N + T_{N+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Binomial random number generation\n",
    "genbin <- function(n, p) {\n",
    "    u <- runif(n)\n",
    "    x <- sum(u < p)\n",
    "}\n",
    "n <- 10; p <- 0.6\n",
    "nsamp <- 1000\n",
    "x <- numeric(nsamp)\n",
    "for (i in seq_len(nsamp)) {\n",
    "    x[i] <- genbin(n, p)\n",
    "}\n",
    "bindata <- data.frame(x)\n",
    "plt <- ggplot(bindata, aes(x=x)) + geom_histogram(binwidth=0.25)\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative binomial random number generation\n",
    "gengeom <- function(p, nsamp=1) {\n",
    "    u <- runif(nsamp)\n",
    "    y <- log(u) / log(1 - p)\n",
    "    ceiling(y)\n",
    "}    \n",
    "nsamp <- 1000\n",
    "p <- 0.6\n",
    "r <- 5\n",
    "x <- numeric(nsamp)\n",
    "for (i in seq_len(r)) {\n",
    "    x <- x + gengeom(p, nsamp)\n",
    "}\n",
    "negbindata <- data.frame(x)\n",
    "plt <- ggplot(negbindata, aes(x=x)) + geom_histogram(binwidth=0.25)\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisson random number generation\n",
    "genpoi <- function(lam, maxiter=1000) {\n",
    "    u_cum <- 1.0\n",
    "    k <- 0\n",
    "    while (u_cum > exp(-lam) && k < maxiter ) {\n",
    "        u <- runif(1)\n",
    "        u_cum <- u_cum * u\n",
    "        k <- k + 1\n",
    "    }\n",
    "    k\n",
    "}\n",
    "lam <- 3  # Poisson rate\n",
    "nsamp <- 1000\n",
    "x <- numeric(nsamp)\n",
    "for (i in seq_len(nsamp)) {\n",
    "    x[i] <- genpoi(lam)\n",
    "}\n",
    "poidata <- data.frame(x)\n",
    "plt <- ggplot(poidata, aes(x=x)) + geom_histogram(binwidth=0.25)\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-square\n",
    "\n",
    "1. Generate $Z_1, \\dotsc, Z_{\\nu} \\stackrel{iid}{\\sim} N(0, 1)$.\n",
    "2. Let $X_{\\nu} = \\sum_{i=1}^{\\nu} Z_i^2$.\n",
    "3. Then $X_{\\nu} \\sim \\chi^2(\\nu)$.\n",
    "\n",
    "Alternatively, for even $\\nu$:\n",
    "\n",
    "1. Generate $U_i \\stackrel{iid}{\\sim} \\text{unif}(0, 1)$.\n",
    "2. Let $X_{\\nu} = -2\\log(\\prod_{i=1}^{\\nu/2} U_i)$.\n",
    "3. Then $X_{\\nu} \\sim \\chi^2(\\nu)$.\n",
    "\n",
    "This is because $\\chi^2(\\nu) = \\text{Gamma}(\\nu/2, 2)$, where 2 is the scale parameter.\n",
    "\n",
    "### Student's $t$\n",
    "\n",
    "1. Generate $Z \\sim N(0, 1)$ and $X \\sim \\chi^2(\\nu)$ independently.\n",
    "2. Let $T = Z / \\sqrt{X/\\nu}$.\n",
    "3. Then $T \\sim t(\\nu)$.\n",
    "\n",
    "### $F$\n",
    "\n",
    "1. Generate $X_1 \\sim \\chi^2(\\nu_1)$ and $X_2 \\sim \\chi^2(\\nu_2)$ independently.\n",
    "2. Let $$F = \\frac{X_1/\\nu_1}{X_2/\\nu_2}.$$\n",
    "3. The $F \\sim F(\\nu_1, \\nu_2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## chi-square random number generation\n",
    "genchisq1 <- function(nsamp, nu) {\n",
    "    z <- matrix(rnorm(nsamp * nu), nrow=nsamp)\n",
    "    rowSums(z^2)\n",
    "}\n",
    "nu <- 6\n",
    "n <- 1000\n",
    "chisqdata1 <- data.frame(x = genchisq(n, nu))\n",
    "plt <- ggplot(chisqdata1, aes(x=x)) +  \n",
    "    geom_histogram(binwidth=0.25, fill=\"white\", color=\"black\") + \n",
    "    geom_density(aes(y=0.25 * ..count..), color=\"purple\")\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## chi-square random number generation 2\n",
    "genchisq2 <- function(nsamp, nu) {\n",
    "    u <- matrix(runif(nsamp * nu / 2), nrow=nsamp)\n",
    "    -2 * log(apply(u, 1, prod) )\n",
    "}\n",
    "nu <- 6\n",
    "n <- 1000\n",
    "chisqdata2 <- data.frame(x = genchisq2(n, nu))\n",
    "plt <- ggplot(chisqdata2, aes(x=x)) +  \n",
    "    geom_histogram(binwidth=0.25, fill=\"white\", color=\"black\") + \n",
    "    geom_density(aes(y=0.25 * ..count..), color=\"purple\")\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Student's t random number generation\n",
    "gent <- function(nsamp, nu) {\n",
    "    z <- rnorm(nsamp)\n",
    "    chisq <- genchisq1(nsamp, nu)\n",
    "    trv <- z / sqrt(chisq / nu)\n",
    "}\n",
    "nu <- 6\n",
    "n <- 1000\n",
    "tdata <- data.frame(x = gent(n, nu))\n",
    "plt <- ggplot(tdata, aes(x=x)) +  \n",
    "    geom_histogram(binwidth=0.25, fill=\"white\", color=\"black\") + \n",
    "    geom_density(aes(y=0.25 * ..count..), color=\"purple\")\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F random number generation\n",
    "genF <- function(nsamp, nu1, nu2) {\n",
    "    chisq1 <- genchisq1(nsamp, nu1)\n",
    "    chisq2 <- genchisq1(nsamp, nu2)\n",
    "    Frv <- chisq1 / nu1 / chisq2 * nu2\n",
    "}\n",
    "nu1 <- 10; nu2 <- 6\n",
    "n <- 1000\n",
    "Fdata <- data.frame(x = genF(n, nu1, nu2))\n",
    "plt <- ggplot(Fdata, aes(x=x)) +  \n",
    "    geom_histogram(binwidth=0.25, fill=\"white\", color=\"black\") + \n",
    "    geom_density(aes(y=0.25 * ..count..), color=\"purple\")\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceptance-rejection sampling (or just rejection sampling)\n",
    "\n",
    "Suppose we want to sample from a distribution with complicated density $f(x)$. It is not easy to use the above method since neither the cdf nor its inverse is analytically available.\n",
    "\n",
    "John von Neumann, while working on the Mahanttan Project, suggested the following:\n",
    "\n",
    "1. Find the \"envelope\" of $f$, i.e., a simple density $g(x)$ such that \n",
    "$$\n",
    "    f(x) \\le c g(x) =: h(x)\n",
    "$$\n",
    "for all $x$, for some constant $c > 0$.\n",
    "\n",
    "2. Sample a random variable $X$ distributed according to $g$. \n",
    "\n",
    "3. Accept $X$ as a representative of $f$ if\n",
    "    - $U \\le \\displaystyle\\frac{f(X)}{h(X)}$,\n",
    "    - where $U$ is a uniform random variable on $[0, 1]$ drawn independently.\n",
    "    \n",
    "4. Reject $X$ otherwise. Go to Line 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why AR sampling works?\n",
    "\n",
    "**Definition** (Body of a function). For a nonnegative, integrable function $f$, its body is defined and denoted by\n",
    "$$\n",
    "    B_f = \\{(x, y): 0 \\le y \\le f(x) \\}.\n",
    "$$\n",
    "\n",
    "- Thus the volume  $B_f$ is $|B_f| = \\int_{-\\infty}^{\\infty}f(x)dx = \\int_{-\\infty}^{\\infty}\\int_0^{f(x)}1dydx$.\n",
    "\n",
    "**Theorem 1**. Supose random variable $X$ has density $g$,  $U\\sim\\text{unif}[0, 1]$ is independent of $X$, and there exists $c > 0$ such that $f(x) \\le c g(x)$ for all $x$. Then, the random vector $(X, cg(X)U)$ is uniformly distributed over the body $B_{cg}$ of $cg$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Theorem 1 states that the AR sampling scheme uniformly samples from $B_{cg}=B_h$.\n",
    "- The sample is accepted if and only if $0 \\le h(X)U = cg(X)U = Y \\le f(X)$, i.e., $(X, Y) \\in B_f$. The conditional density of $(X, Y)$ given $\\{(X, Y) \\in B_f\\}$ is merely\n",
    "$$\n",
    "    \\frac{|B_{cg}|^{-1}\\mathbb{I}_{B_{cg}}(x,y)}{P(B_f)}\\mathbb{I}_{B_f}(x,y)\n",
    "    = \\frac{|B_{cg}|^{-1}\\mathbb{I}_{B_{cg}}(x,y)}{|B_f|/|B_{cg}|}\\mathbb{I}_{B_f}(x,y)\n",
    "    = \\frac{1}{|B_f|}\\mathbb{I}_{B_f}(x,y)\n",
    "    .\n",
    "$$\n",
    "That is, $(X,Y)|\\{(X, Y)\\in B_f\\} \\sim \\text{unif}(B_f)$.\n",
    "    + This means the accepted sample $(X, Y)$ is drawn according to $\\text{unif}(B_f)$.\n",
    "- Now the marginal density of $X$ is $f$. To see this, note when $(X, Y) \\sim \\text{unif}(B_f)$,\n",
    "\\begin{align*}\n",
    "    P(X \\in A) &= \\frac{|B_{\\bar{A}}|}{|B_f|},\n",
    "    \\quad\n",
    "    \\bar{A} = B_f \\cap \\{(x, y): x\\in A\\} = \\{(x, y): x \\in A, ~ 0 \\le y \\le f(x)\\}.\n",
    "    \\\\\n",
    "    &= \\frac{\\int_A f(x)dx}{1}, \\quad \\because |B_f| = \\int_{-\\infty}^{\\infty}f(x)dx = 1\n",
    "    \\\\\n",
    "    &= \\int_A f(x)dx.\n",
    "\\end{align*}\n",
    "\n",
    "- Thus sample $X$ is drawn according to $f$!\n",
    "\n",
    "- The total acceptance ratio is\n",
    "\\begin{align*}\n",
    "    P\\left(U \\le \\frac{f(X)}{cg(X)}\\right) \n",
    "    &= \\int_{-\\infty}^{\\infty}\\int_{0}^{f(x)/[cg(x)]} 1\\cdot g(x) du dx \\\\\n",
    "    &= \\int_{-\\infty}^{\\infty} g(x) \\int_{0}^{f(x)/[cg(x)]} 1 du dx \\\\\n",
    "    &= \\int_{-\\infty}^{\\infty} g(x) \\frac{f(x)}{cg(x)}  dx \\\\\n",
    "    &= \\int_{-\\infty}^{\\infty} \\frac{f(x)}{c}dx \\\\\n",
    "    &= \\frac{1}{c} \\int_{-\\infty}^{\\infty} f(x) dx \\\\\n",
    "    &= \\frac{1}{c}\n",
    "    .\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proof of Theorem 1\n",
    "\n",
    "We want to show that the joint density of $(X, cg(X)U)$ is \n",
    "$$\\frac{1}{|B_{cg}|}\\mathbb{I}_{B_{cg}}(x, y).$$\n",
    "\n",
    "Let $Y = cg(X)U$. Then $Y|\\{X=x\\}  = cg(x) U \\sim \\text{unif}[0, cg(x)]$. That is, the conditional density of $Y$ given $X$ is\n",
    "$$\n",
    "    p_{Y|X}(y|x) = \\frac{1}{cg(x)}\\mathbb{I}_{[0, cg(x)]}(y).\n",
    "$$\n",
    "By construction, the marginal density of $X$ is given by $p_X(x) = g(x)$. Therefore the joint density of $(X, Y)$ is\n",
    "\\begin{align*}\n",
    "    p_{XY}(x, y) &= p_X(x)p_{Y|X}(y|x) = \\frac{1}{c}\\mathbb{I}_{[0, cg(x)]}(y) \\\\\n",
    "    &= \\begin{cases} 1/c, & \\text{if } 0 \\le y \\le c g(x), \\\\\n",
    "        0, & \\text{otherwise}. \\end{cases}\n",
    "    \\\\\n",
    "    &= \\frac{1}{c}\\mathbb{I}_{B_{cg}}(x,y).\n",
    "\\end{align*}\n",
    "Now since\n",
    "$$\n",
    "    1 = \\int_{-\\infty}^{\\infty}\\int_0^{cg(x)}\\frac{1}{c}dydx = \\frac{1}{c}|B_{cg}|,\n",
    "$$\n",
    "we have\n",
    "$\\frac{1}{|B_{cg}|}\\mathbb{I}_{B_{cg}}(x, y)$\n",
    "as desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Marsaglia\n",
    "\n",
    "> One way to sample from the unit disk is to sample $(U, V)$ from $\\text{unif}[-1, 1]\\times\\text{unif}[-1, 1]$, and discard the sample if $U^2 + V^2 > 1$ and resample.\n",
    "\n",
    "We have $X=(U, V)$.\n",
    "\n",
    "* Target density: $f(u, v) = \\frac{1}{\\pi}\\mathbb{I}_{\\{u^2+v^2<1\\}}(u, v)$ (uniform from unit disc)\n",
    "* Sampling density: $g(u, v) = \\frac{1}{4}\\mathbb{I}_{\\{|u|<1, |v|<1\\}}(u, v)$ (uniform from $[-1, 1]^2$)\n",
    "* Envelope: $h(u, v) = \\frac{1}{\\pi}\\mathbb{I}_{|u|<1, |v|<1}(u, v) = \\frac{4}{\\pi}g(u, v)$, hence $c=4/\\pi$.\n",
    "* Accptance criterion\n",
    "$$\n",
    "\\frac{f(U,V)}{h(U,V)} = \\frac{\\mathbb{I}_{\\{U^2+V^2 < 1\\}}}{\\mathbb{I}_{\\{|U| < 1, |V| < 1\\}}}\n",
    "= \\begin{cases} 1, & \\text{if } U^2 + V^2 < 1 \\\\ 0, & \\text{otherwise} \\end{cases}\n",
    "$$\n",
    "* Thus we accept the sample from $g$ iff $U^2 + V^2 < 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: gamma random numbers\n",
    "\n",
    "Recall that the Gamma distribution with shape parameter $\\alpha$ and scale parameter $\\beta$ has density\n",
    "$$\n",
    "    f_{\\Gamma}(x; \\alpha, \\beta) = \\frac{1}{\\Gamma(\\alpha)\\beta^{\\alpha}}x^{\\alpha-1}e^{-x/\\beta}\n",
    "$$\n",
    "for $x \\ge 0$. If $X \\sim \\text{Gamma}(\\alpha, \\beta)$, then $cX \\sim \\text{Gamma}(\\alpha, c\\beta)$.\n",
    "Hence it suffices to sample from $\\text{Gamma}(\\alpha, 1)$. Furthermore, $X\\sim \\text{Gamma}(\\alpha, 1)$ and  $\\alpha > 1$, then $X \\stackrel{d}{=} Y + Z$ where $Y \\sim \\text{Gamma}(\\lfloor \\alpha \\rfloor, 1)$, $Z \\sim \\text{Gamma}(\\alpha - \\lfloor \\alpha \\rfloor, 1)$ and independent of $Y$. \n",
    "The $Y$ can be generated by summing $\\lfloor \\alpha \\rfloor$ independent $\\text{Exp}(1)$ random variables.\n",
    "Therefore we only need to sample from \n",
    "$\\text{Gamma}(\\alpha, 1)$, $\\alpha \\in (0, 1)$.\n",
    "\n",
    "If $0 < \\alpha < 1$, we see that\n",
    "$$\n",
    "    x^{\\alpha - 1}e^{-x} \\le \\begin{cases} x^{\\alpha - 1}, & \\text{if } 0 \\le x \\le 1, \\\\ e^{-x}, & \\text{otherwise}. \\end{cases}\n",
    "$$\n",
    "Thus we choose \n",
    "$$\n",
    "    h(x) = \\begin{cases} x^{\\alpha - 1}/\\Gamma(\\alpha), & \\text{if } 0 \\le x \\le 1, \\\\ e^{-x}/\\Gamma(\\alpha), & \\text{otherwise}. \\end{cases}\n",
    "$$\n",
    "leading to\n",
    "$$\n",
    "    g(x) = \\begin{cases} x^{\\alpha - 1}/(1/\\alpha + 1/e), & \\text{if } 0 \\le x \\le 1, \\\\ e^{-x}/(1/\\alpha + 1/e), & \\text{otherwise}. \\end{cases}    \n",
    "$$\n",
    "and\n",
    "$$\n",
    "    c = \\frac{1}{\\Gamma(\\alpha)}\\left(\\frac{1}{\\alpha} + \\frac{1}{e}\\right).\n",
    "$$\n",
    "Density $g$ has cdf\n",
    "$$\n",
    "    G(x) = \\begin{cases} x^{\\alpha}/(1 + \\alpha/e), & \\text{if } 0 \\le x \\le 1, \\\\ \n",
    "        \\frac{1 + \\alpha/e - \\alpha e^{-x}}{1 + \\alpha/e}, & \\text{otherwise}. \\end{cases}    \n",
    "$$\n",
    "whose inverse is\n",
    "$$\n",
    "    G^{-1}(u) = \\begin{cases} [(1 + \\alpha/e)u]^{1/\\alpha}, & \\text{if } 0 \\le u \\le 1/[1+\\alpha/e], \\\\ \n",
    "        -\\log(1/\\alpha + 1/e) - \\log(1 - u), & 1/[1+\\alpha/e] \\le u < 1. \\end{cases}    \n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gengamma_ar <- function(nsamp, alph) {\n",
    "    # sample X from g\n",
    "    v <- runif(nsamp)  # unif rv for inverse method\n",
    "    idx <- v > 1 / (1 + alph * exp(-1))\n",
    "    x <- numeric(nsamp)\n",
    "    x[idx]  = -log(1 / alph + exp(-1)) - log(1 - v[idx])\n",
    "    x[!idx] = ((1 + alph * exp(-1)) * v[!idx])^(1 / alph)\n",
    "    \n",
    "    # test acceptance\n",
    "    u <- runif(nsamp)\n",
    "    idx2 <- (x > 1)\n",
    "    accept <- logical(nsamp)\n",
    "    accept[idx2]  <- (u[idx2] < x[idx2]^(alph - 1))\n",
    "    accept[!idx2] <- (u[!idx2] < exp(-x[!idx2]))\n",
    "    \n",
    "    x[accept]\n",
    "}\n",
    "\n",
    "n <- 2000\n",
    "alph <- 0.5\n",
    "x <- gengamma_ar(n, alph) \n",
    "length(x)\n",
    "length(x) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma(0.5) / (1 / alph + exp(-1) )   # acceptance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamdata <- data.frame(x = x)\n",
    "plt <- ggplot(gamdata, aes(x=x)) +  \n",
    "    geom_histogram(binwidth=0.25, fill=\"white\", color=\"black\") + \n",
    "    geom_density(aes(y=0.25 * ..count..), color=\"purple\")\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate random numbers\n",
    "\n",
    "### Batch methods\n",
    "\n",
    "#### Multinomial\n",
    "\n",
    "Suppose we want to sample $(X_1, \\dotsc, X_k) \\sim \\text{mult}(n, p_1, \\dotsc, p_k)$, where $\\sum_{i=1}^k p_i = 1$, $\\sum_{i=1}^n X_i = n$.\n",
    "\n",
    "* Method 1: draw $n$ independent realization from pmf $(p_1, \\dotsc, p_k)$. \n",
    "    + An easy way is to declare category $j$, $j \\in \\{1, \\dotsc, k\\}$ if \n",
    "$$\n",
    "    U \\in \\left[\\sum_{k=0}^{j-1} p_k, \\sum_{k=0}^{j} p_k \\right),\n",
    "$$\n",
    "    where $U \\sim \\text{unif}[0, 1]$. Take $p_0 = 0$.\n",
    "    \n",
    "* Method 2: sample $k$ independent Poisson random variables $(X_1, \\dotsc, X_k)$ with means $\\lambda p_1, \\dotsc, \\lambda p_k$. If the total number of successes $\\sum_{i=1}^k X_i$ is equal to $n$, then the conditional distribution of $(X_1, \\dotsc, X_k)$ is the desired multinomial.\n",
    "    + We must be fortunate for the sum to be exactly $n$.\n",
    "    \n",
    "#### Multivariate normal\n",
    "\n",
    "Suppose we want to sample $\\mathbf{X} = (X_1, \\dotsc, X_p)$ from MVN $N(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$. If we can find $\\mathbf{L} \\in \\mathbb{R}^{p \\times p}$ such that $\\mathbf{L}^T\\mathbf{L} = \\boldsymbol{\\Sigma}$, then \n",
    "$$\n",
    "    \\mathbf{L}^T\\mathbf{Z} + \\boldsymbol{\\mu}, \\quad \\mathbf{Z} \\sim N(0, \\mathbf{I}_p)\n",
    "$$\n",
    "follows the desired distribution.\n",
    "\n",
    "* Random vector $\\mathbf{Z}$ consists of $p$ independent standard normal random numbers.\n",
    "\n",
    "* Possible choices of $\\mathbf{L}$ are:\n",
    "\n",
    "    + Cholesky decomposition of $\\boldsymbol{\\Sigma}$: $\\mathbf{L}$ is lower triangular.\n",
    "    + Matrix square root: if $\\mathbf{Q}\\boldsymbol{\\Lambda}\\mathbf{Q}^T$ is a eigenvalue decomposition of $\\boldsymbol{\\Sigma}$, where $\\boldsymbol{\\Lambda} = \\text{diag}(\\lambda_1, \\dotsc, \\lambda_p)$ with $\\lambda_i \\ge 0$, then\n",
    "$$\n",
    "    \\mathbf{L} = \\mathbf{Q}\\boldsymbol{\\Lambda}^{1/2}\\mathbf{Q}^T,\n",
    "    \\quad\n",
    "    \\boldsymbol{\\Lambda}^{1/2} = \\text{diag}(\\lambda_1^{1/2}, \\dotsc, \\lambda_p^{1/2})\n",
    "    .\n",
    "$$\n",
    "such a matrix is symmetric and positive semidefinite, and is often denoted by $\\boldsymbol{\\Sigma}^{1/2}$.\n",
    "\n",
    "* For large $p$, finding such a decomposition is challenging.\n",
    "\n",
    "#### Multivariate $t$\n",
    "\n",
    "A multivariate $t$ distribution with degrees of freedom $\\nu$, scale matrix $\\boldsymbol{\\Sigma}$, and location vector $\\boldsymbol{\\mu}$ is the distribution of the random vector\n",
    "$$\n",
    "    \\mathbf{T} = \\frac{1}{\\sqrt{\\chi^2_{\\nu}/\\nu}}\\mathbf{X} + \\boldsymbol{\\mu},\n",
    "$$\n",
    "where $\\mathbf{X} \\sim N(0, \\boldsymbol{\\Sigma})$, and $\\chi^2_{\\nu}$ is the chi-square random variable with $\\nu$ degrees of freedom, independent of $\\mathbf{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential sampling\n",
    "\n",
    "In many cases we can sample a random vector by sampling each component in turn and conditioning:\n",
    "\\begin{align*}\n",
    "    p_{X_1, \\dotsc, X_p}(x_1, \\dotsc, x_p) \n",
    "    &= p_{X_1}(x_1)\\prod_{j=2}^p p_{X_j|X_1, \\dotsc, X_{j-1}}(x_j | x_1, \\dotsc, x_{j-1}) \\\\\n",
    "    &= p_{X_1}(x_1)p_{X_2|X_1}(x_2|x_1) \\prod_{j=3}^p p_{X_j|X_2, \\dotsc, X_{j-1}}(x_j | x_1, \\dotsc, x_{j-1}) \\\\\n",
    "    &= \\dotsb\n",
    "\\end{align*}\n",
    "\n",
    "#### Multinomial\n",
    "\n",
    "For $(X_1, \\dotsc, X_k) \\sim \\text{mult}(n, p_1, \\dotsc, p_k)$, it is immediate to see that $X_1 \\sim B(n, p_1)$. Given $X_1 = x_1$, $(X_2, \\dotsc, X_k) \\sim \\text{mult}(n - x_1, p_2 / (1 - p_1), \\dotsc, p_k / (1 - p_1) )$. Hence $X_2 | \\{X_1 = x_1\\} \\sim B(n - x_1, p_2 / (1 - p_1) )$ and so on.\n",
    "\n",
    "#### Multivariate normal\n",
    "\n",
    "If we want to sample $\\mathbf{X} = (X_1, \\dotsc, X_p)$ from MVN with mean $\\boldsymbol{\\mu}=(\\mu_1, \\dotsc, \\mu_p)^T$ and covariance matrix $\\boldsymbol{\\Sigma} = (\\sigma_{ij})$, then note that the first component $X_1 \\sim N(\\mu_1, \\sigma_{11})$. From the conditional distribution formula for multivariate normal, we see that\n",
    "$$\n",
    "    (X_2, \\dotsc, X_p) | \\{X_1 = x_1\\}\n",
    "    \\sim N(\\bar{\\boldsymbol{\\mu}}, \\bar{\\boldsymbol{\\Sigma}}),\n",
    "    \\quad\n",
    "    \\bar{\\boldsymbol{\\mu}} = \\boldsymbol{\\mu}_2 + \\boldsymbol{\\Sigma}_{12}^T(x_1 - \\mu_1)/\\sigma_{11},\n",
    "    ~\n",
    "    \\bar{\\boldsymbol{\\Sigma}} = \\boldsymbol{\\Sigma}_{22} - \\boldsymbol{\\Sigma}_{12}^T\\boldsymbol{\\Sigma}_{12}/\\sigma_{11}\n",
    "$$\n",
    "if we partition\n",
    "\\begin{align*}\n",
    "    \\boldsymbol{\\mu} &= (\\mu_1, \\boldsymbol{\\mu}_2)^T \\\\\n",
    "    \\boldsymbol{\\Sigma} &= \\begin{bmatrix}\n",
    "        \\sigma_{11} & \\boldsymbol{\\Sigma}_{12} \\\\\n",
    "        \\boldsymbol{\\Sigma}_{12}^T & \\boldsymbol{\\Sigma}_{22}\n",
    "        \\end{bmatrix}  \n",
    "     .\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "441.3333435058594px",
    "left": "0px",
    "right": "903.3333129882813px",
    "top": "140.6666717529297px",
    "width": "166px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
